# -*- coding: utf-8 -*-
"""Latihan - TimeSeries.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zr7oqFFj9sZGpr1zCk6Z3a8vRLan84Vg
"""

! chmod 600 /content/kaggle.json

! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d rober2598/madrid-weather-dataset-by-hours-20192022

import zipfile
zip_file = zipfile.ZipFile('/content/madrid-weather-dataset-by-hours-20192022.zip')
zip_file.extractall('/tmp/')

import numpy as np
import pandas as pd
from keras.layers import Dense, LSTM, Bidirectional
import matplotlib.pyplot as plt
import tensorflow as tf

data_train = pd.read_csv('/tmp/weather_madrid_2019-2022.csv')
data_train = data_train.iloc[:5000]
data_train

data_train.isnull().sum()

data_train['Day'] = 1
data_train['time'] = pd.to_datetime( data_train['time'] , format="%Y/%m/%d")

data_train.info()

dates = data_train['time'].values
temp  = data_train['temperature'].values
 
plt.figure(figsize=(15,5))
plt.plot(dates, temp)
plt.title('Temperature average',
          fontsize=20);

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(temp, dates, test_size = 0.2, random_state = 0 , shuffle=False)
print(len(x_train), len(x_test))

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler() 
data_scaled = scaler.fit_transform(x_train.reshape(-1,1)).reshape(-1)
threshold_mae = (data_scaled.max() - data_scaled.min()) * 0.1
threshold_mae

tf.keras.backend.set_floatx('float64')
train_set = windowed_dataset(x_train, window_size=60, batch_size=4, shuffle_buffer=1000)

model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(60, return_sequences=True),
  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(60)),
  tf.keras.layers.Dense(16, activation="relu"),
  tf.keras.layers.Dense(8, activation="relu"),
  tf.keras.layers.Dense(1),
])

# callback
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae')< threshold_mae):
      self.model.stop_training = True
      print("\nMAE of the model < 10% of data scale")
callbacks = myCallback()

optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer="adam",
              metrics=["mae"])
history = model.fit(train_set,epochs=100,  batch_size=4, callbacks=[callbacks])

